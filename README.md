# ğŸ§  AI_DATA_EXTRACTION_AND_SEARCH_V1

A modular, local-first pipeline that ingests and understands healthcare, regulatory, and research documents. Extracts clean text, summarizes, embeds locally using Ollama, and enables a private, grounded Q&A experience â€” all without needing OpenAI or cloud services.

---

## âœ… Key Features

### ğŸ§¾ Document Processing Pipeline
- Multi-format ingestion: `PDF`, `DOCX`, `TXT`, image scans
- OCR via Tesseract for image-based files
- Text extraction â†’ normalization â†’ optional LLM post-processing
- Configurable output in `JSON`, `TXT`, or `Markdown`
- Automatic refresh logic using file hashing
- Summarization, tagging, and classification via OpenAI, Gemini, or local LLM

### ğŸ’¬ Smart Chatbot (RAG-Enabled)
- Local embedding via `nomic-embed-text` on Ollama
- Retrieval by cosine similarity over document chunks
- Response generation via `mistral` (also on Ollama)
- Prompts are grounded: no hallucinations, no unsupported claims
- Full logging and modular design for long-term scalability

---

## ğŸ“‚ Project Structure

CURATED_INFORMATION/
â”œâ”€â”€ documents/
â”‚ â”œâ”€â”€ input_folder/ # Place raw source documents here
â”‚ â””â”€â”€ output_folder/ # JSON outputs with text + embeddings
â”œâ”€â”€ logs/ # Log outputs and embeddings inspection
â”œâ”€â”€ cache/ # Hashes for refresh detection
â”œâ”€â”€ pipeline/ # Ingestion, extraction, normalization, embedding
â”‚ â”œâ”€â”€ ingestion.py
â”‚ â”œâ”€â”€ extract.py
â”‚ â”œâ”€â”€ normalize.py
â”‚ â”œâ”€â”€ embedding_generator.py
â”‚ â”œâ”€â”€ output.py
â”‚ â”œâ”€â”€ refresh.py
â”‚ â”œâ”€â”€ doc_classifier.py # (planned) Auto-tagging of document types
â”‚ â””â”€â”€ logger.py
â”œâ”€â”€ smart_chatbot/ # Chatbot + retrieval-augmented generation (RAG)
â”‚ â”œâ”€â”€ runner.py
â”‚ â”œâ”€â”€ embedder.py
â”‚ â”œâ”€â”€ retriever.py
â”‚ â”œâ”€â”€ generator.py
â”‚ â”œâ”€â”€ prompts.py
â”‚ â”œâ”€â”€ utils.py
â”‚ â””â”€â”€ logger.py
â”œâ”€â”€ validate_embeddings.py # Validates embedding structure and similarity
â”œâ”€â”€ config.yaml # Central configuration
â”œâ”€â”€ .env # Ollama + model overrides
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copy
Edit

---

## âš™ï¸ Setup Instructions

### 1. ğŸ§ª Create and activate your virtual environment
```bash
python -m venv .venv
source .venv/bin/activate
2. ğŸ“¥ Install Python dependencies
bash
Copy
Edit
pip install --upgrade pip
pip install -r requirements.txt
3. ğŸ”§ Install OCR & PDF tools (for Ubuntu)
bash
Copy
Edit
sudo apt install tesseract-ocr poppler-utils
ğŸ” Ollama Setup (Local LLMs & Embedding)
Make sure you have Ollama installed. Then:

bash
Copy
Edit
ollama run nomic-embed-text
ollama run mistral
ğŸš€ Running the Document Pipeline
Place your files into documents/input_folder/, then run:

bash
Copy
Edit
python document_pipeline_main.py --config config.yaml
Outputs will be saved to documents/output_folder/ as .json.

ğŸ’¬ Running the Smart Local Chatbot
To chat with a processed document:

bash
Copy
Edit
python -m smart_chatbot.runner --config config.yaml --file documents/output_folder/your_doc.json
Chat will use nomic-embed-text to embed your question, retrieve top chunks, and answer using mistral.

ğŸ“¦ Example Output File
json
Copy
Edit
{
  "metadata": {
    "source_file": "cost-manual-2016.pdf",
    "detected_type": "COST_MANUAL",
    "pages": 18,
    "extracted_at": "2025-06-15T13:12:04"
  },
  "chunks": [
    {
      "id": 1,
      "text": "The unit cost of item X is derived from...",
      "embedding": [0.013, 0.248, ...]
    },
    ...
  ],
  "llm_output": {
    "summary": "This manual defines unit costs...",
    "tags": ["costing", "healthcare", "PBAC"],
    "classification": "COST_MANUAL"
  }
}
ğŸ” Validation Tools
Run embedding validation:
bash
Copy
Edit
python validate_embeddings.py --file documents/output_folder/your_doc.json --logdir logs
Verifies embedding shapes

Computes cosine similarity between chunks

Plots embeddings with PCA

ğŸ”§ Config Management
Configuration is loaded from config.yaml and can be overridden by .env.

Example .env:

env
Copy
Edit
EMBEDDING_MODEL=nomic-embed-text
LLM_MODEL=mistral
OLLAMA_EMBED_URL=http://localhost:11434/api/embeddings
OLLAMA_CHAT_URL=http://localhost:11434/api/chat
TOP_K=3
CHUNK_SIZE=400
CHUNK_OVERLAP=50
LOG_DIR=logs
ğŸ§  What's Next
 Implement doc_classifier.py to auto-detect document types

 Add FAISS or Chroma integration for scale

 Enable multi-document Q&A

 Build Streamlit or web UI

 Add citation-based answering

ğŸ¤ Credits
Crafted by Mithun + Bruce (ChatGPT), designed for real-world document intelligence at scale â€” in healthcare, regulation, and policy domains.

ğŸ“ License
MIT License â€“ use, remix, and build your own local-AI-powered search!

yaml
Copy
Edit

---

Would you like this saved as a downloadable `.md` file as well? Or want a visual diagram (architecture flo# pbac_rag
# pbac_rag
# pbac_rag_2
# pbac_rag_2
